{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd07b743127f8f4c955843e2abebe4405e9e9befcc023b2719b748b063e552479ec",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "D:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "D:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from model import PQRNN\n",
    "from dataset import create_dataloaders,DummyDataset\n",
    "model = PQRNN(b=128,d=64,output_size=6,dropout=0.5,lr=1e-3,num_layers=1,fc_sizes=[128,64],rnn_type='GRU',multilabel=True)#.load_from_checkpoint(checkpoint_path='checkpoints.ckpt',map_location=torch.device('cpu'),hparams_file='lightning_logs/default/version_0/hparams.yaml')\n",
    "\n",
    "df = pd.read_csv('data/test.csv')\n",
    "#test_dataset = DummyDataset(df[['comment_text']].to_dict('records'),has_label=False,feature_size=128*2,add_eos_tag=True,add_bos_tag=True,max_seq_len=512,label2index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PQRNN(\n",
       "  (tanh): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (qrnn): GRU(128, 64, dropout=0.5, bidirectional=True)\n",
       "  (output): ModuleList(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=6, bias=True)\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.3298, 0.0925, 0.1864, 0.1180, 0.1912, 0.1533],\n",
      "        [0.3328, 0.0969, 0.1912, 0.1229, 0.1955, 0.1586],\n",
      "        [0.3232, 0.0875, 0.1793, 0.1133, 0.1848, 0.1466],\n",
      "        [0.3126, 0.0811, 0.1731, 0.1060, 0.1765, 0.1395],\n",
      "        [0.3369, 0.0923, 0.1814, 0.1224, 0.1964, 0.1542],\n",
      "        [0.3405, 0.0997, 0.1941, 0.1261, 0.2012, 0.1612],\n",
      "        [0.3818, 0.1197, 0.2128, 0.1526, 0.2369, 0.1875],\n",
      "        [0.3380, 0.0961, 0.1903, 0.1221, 0.1975, 0.1572],\n",
      "        [0.3269, 0.0919, 0.1858, 0.1177, 0.1896, 0.1523],\n",
      "        [0.3934, 0.1267, 0.2291, 0.1537, 0.2447, 0.1936],\n",
      "        [0.3408, 0.0965, 0.1938, 0.1229, 0.2003, 0.1591],\n",
      "        [0.3557, 0.1052, 0.2029, 0.1317, 0.2119, 0.1689],\n",
      "        [0.3579, 0.1052, 0.2012, 0.1331, 0.2130, 0.1693],\n",
      "        [0.3471, 0.0993, 0.1950, 0.1266, 0.2047, 0.1631],\n",
      "        [0.3354, 0.0968, 0.1912, 0.1226, 0.1961, 0.1579],\n",
      "        [0.3778, 0.1208, 0.2182, 0.1490, 0.2323, 0.1861],\n",
      "        [0.3828, 0.1184, 0.2153, 0.1480, 0.2346, 0.1850],\n",
      "        [0.3299, 0.0907, 0.1841, 0.1158, 0.1905, 0.1505],\n",
      "        [0.3359, 0.0961, 0.1908, 0.1217, 0.1970, 0.1573],\n",
      "        [0.3502, 0.1015, 0.1962, 0.1291, 0.2074, 0.1651],\n",
      "        [0.3174, 0.0843, 0.1753, 0.1087, 0.1803, 0.1423],\n",
      "        [0.3563, 0.1065, 0.2023, 0.1330, 0.2130, 0.1691],\n",
      "        [0.3328, 0.0949, 0.1889, 0.1214, 0.1944, 0.1562],\n",
      "        [0.3305, 0.0925, 0.1858, 0.1179, 0.1923, 0.1525],\n",
      "        [0.3314, 0.0948, 0.1903, 0.1213, 0.1943, 0.1562],\n",
      "        [0.3244, 0.0882, 0.1806, 0.1137, 0.1861, 0.1474],\n",
      "        [0.3051, 0.0757, 0.1657, 0.0998, 0.1693, 0.1328],\n",
      "        [0.3519, 0.1059, 0.2020, 0.1326, 0.2094, 0.1681],\n",
      "        [0.3265, 0.0910, 0.1834, 0.1169, 0.1892, 0.1511],\n",
      "        [0.3905, 0.1297, 0.2274, 0.1573, 0.2438, 0.1958],\n",
      "        [0.3844, 0.1151, 0.2109, 0.1456, 0.2346, 0.1822],\n",
      "        [0.3310, 0.0895, 0.1827, 0.1156, 0.1915, 0.1507]],\n",
      "       grad_fn=<SigmoidBackward>) tensor([[0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[0.3107, 0.0799, 0.1707, 0.1044, 0.1748, 0.1379],\n",
      "        [0.3996, 0.1343, 0.2309, 0.1666, 0.2534, 0.2035],\n",
      "        [0.3789, 0.1174, 0.2138, 0.1483, 0.2324, 0.1847],\n",
      "        [0.3196, 0.0874, 0.1798, 0.1129, 0.1832, 0.1467],\n",
      "        [0.3072, 0.0774, 0.1681, 0.1018, 0.1715, 0.1349],\n",
      "        [0.3833, 0.1210, 0.2199, 0.1492, 0.2358, 0.1870],\n",
      "        [0.3103, 0.0803, 0.1723, 0.1048, 0.1750, 0.1390],\n",
      "        [0.3561, 0.1071, 0.2036, 0.1340, 0.2141, 0.1704],\n",
      "        [0.4033, 0.1303, 0.2286, 0.1618, 0.2538, 0.1988],\n",
      "        [0.3338, 0.0937, 0.1863, 0.1201, 0.1941, 0.1546],\n",
      "        [0.3040, 0.0763, 0.1669, 0.1005, 0.1689, 0.1334],\n",
      "        [0.3192, 0.0844, 0.1745, 0.1108, 0.1816, 0.1436],\n",
      "        [0.3696, 0.1109, 0.2054, 0.1399, 0.2230, 0.1760],\n",
      "        [0.3083, 0.0780, 0.1688, 0.1020, 0.1718, 0.1350],\n",
      "        [0.3863, 0.1258, 0.2242, 0.1541, 0.2394, 0.1916],\n",
      "        [0.3377, 0.0965, 0.1898, 0.1228, 0.1986, 0.1578],\n",
      "        [0.3914, 0.1274, 0.2271, 0.1560, 0.2438, 0.1949],\n",
      "        [0.3811, 0.1231, 0.2188, 0.1523, 0.2346, 0.1859],\n",
      "        [0.3585, 0.1086, 0.2058, 0.1346, 0.2149, 0.1712],\n",
      "        [0.3702, 0.1146, 0.2106, 0.1429, 0.2246, 0.1793],\n",
      "        [0.3137, 0.0800, 0.1722, 0.1047, 0.1765, 0.1384],\n",
      "        [0.3212, 0.0856, 0.1784, 0.1108, 0.1833, 0.1452],\n",
      "        [0.3545, 0.1043, 0.2006, 0.1307, 0.2112, 0.1677],\n",
      "        [0.3283, 0.0893, 0.1812, 0.1151, 0.1900, 0.1494],\n",
      "        [0.3345, 0.1046, 0.1930, 0.1350, 0.1991, 0.1612],\n",
      "        [0.3198, 0.0856, 0.1787, 0.1100, 0.1822, 0.1448],\n",
      "        [0.3054, 0.0761, 0.1664, 0.1000, 0.1693, 0.1327],\n",
      "        [0.3679, 0.1109, 0.2032, 0.1433, 0.2250, 0.1775],\n",
      "        [0.3199, 0.0843, 0.1756, 0.1101, 0.1821, 0.1444],\n",
      "        [0.3111, 0.0933, 0.1797, 0.1223, 0.1806, 0.1467],\n",
      "        [0.4059, 0.1325, 0.2335, 0.1625, 0.2555, 0.2007],\n",
      "        [0.3312, 0.0922, 0.1866, 0.1182, 0.1924, 0.1531]],\n",
      "       grad_fn=<SigmoidBackward>) tensor([[0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "dataloader = create_dataloaders(task='toxic',label2index=None,batch_size=32,feature_size=128*2,data_path='data')\n",
    "#dataloader = create_dataloaders(test_dataset)\n",
    "model.eval()\n",
    "for test in dataloader:\n",
    "  for batch in test:\n",
    "    #projections,lengths = batch\n",
    "    projections,length,label = batch\n",
    "    print(torch.sigmoid(model.forward(projections)),label)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PQRNN:\n\tMissing key(s) in state_dict: \"qrnn.weight_ih_l1\", \"qrnn.weight_hh_l1\", \"qrnn.bias_ih_l1\", \"qrnn.bias_hh_l1\", \"qrnn.weight_ih_l1_reverse\", \"qrnn.weight_hh_l1_reverse\", \"qrnn.bias_ih_l1_reverse\", \"qrnn.bias_hh_l1_reverse\", \"qrnn.weight_ih_l2\", \"qrnn.weight_hh_l2\", \"qrnn.bias_ih_l2\", \"qrnn.bias_hh_l2\", \"qrnn.weight_ih_l2_reverse\", \"qrnn.weight_hh_l2_reverse\", \"qrnn.bias_ih_l2_reverse\", \"qrnn.bias_hh_l2_reverse\", \"qrnn.weight_ih_l3\", \"qrnn.weight_hh_l3\", \"qrnn.bias_ih_l3\", \"qrnn.bias_hh_l3\", \"qrnn.weight_ih_l3_reverse\", \"qrnn.weight_hh_l3_reverse\", \"qrnn.bias_ih_l3_reverse\", \"qrnn.bias_hh_l3_reverse\". ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7f8f0a40c7f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoints.ckpt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHECKPOINT_HYPER_PARAMS_KEY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\saving.py\u001b[0m in \u001b[0;36m_load_model_state\u001b[1;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;31m# load the state_dict on the model automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Deep_Learning\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PQRNN:\n\tMissing key(s) in state_dict: \"qrnn.weight_ih_l1\", \"qrnn.weight_hh_l1\", \"qrnn.bias_ih_l1\", \"qrnn.bias_hh_l1\", \"qrnn.weight_ih_l1_reverse\", \"qrnn.weight_hh_l1_reverse\", \"qrnn.bias_ih_l1_reverse\", \"qrnn.bias_hh_l1_reverse\", \"qrnn.weight_ih_l2\", \"qrnn.weight_hh_l2\", \"qrnn.bias_ih_l2\", \"qrnn.bias_hh_l2\", \"qrnn.weight_ih_l2_reverse\", \"qrnn.weight_hh_l2_reverse\", \"qrnn.bias_ih_l2_reverse\", \"qrnn.bias_hh_l2_reverse\", \"qrnn.weight_ih_l3\", \"qrnn.weight_hh_l3\", \"qrnn.bias_ih_l3\", \"qrnn.bias_hh_l3\", \"qrnn.weight_ih_l3_reverse\", \"qrnn.weight_hh_l3_reverse\", \"qrnn.bias_ih_l3_reverse\", \"qrnn.bias_hh_l3_reverse\". "
     ]
    }
   ],
   "source": [
    "model_load = model.load_from_checkpoint('checkpoints.ckpt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import PQRNN\n",
    "from dataset import create_dataloaders,DummyDataset\n",
    "from torch.utils.data import Dataset\n",
    "model = PQRNN(d=256,num_layers=2,rnn_type='GRU',multilabel=True,output_size=6).load_from_checkpoint(checkpoint_path='checkpoints-v3.ckpt',map_location=torch.device('cpu'),hparams_file='lightning_logs/default/version_0/hparams.yaml',strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import collate_fn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "df = pd.DataFrame({'text':[\"stupid ass modders\",\"Fucking nigga\",\"U dumb bitchesss\"]})\n",
    "test_dataset = DummyDataset(df[['text']].to_dict('records'),has_label=False,max_seq_len=128,feature_size=128*2)\n",
    "dataloader = DataLoader(test_dataset,batch_size=1,collate_fn=collate_fn,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.3885, 0.2170, 0.3021, 0.2318, 0.2748, 0.2524]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4354, 0.2803, 0.3554, 0.2860, 0.3300, 0.3035]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4525, 0.2998, 0.3691, 0.3020, 0.3490, 0.3192]],\n",
      "       grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in dataloader:\n",
    "  #print(batch[0])\n",
    "  #projections,lengths = batch\n",
    "  projections,length,label = batch\n",
    "  print(torch.sigmoid(model.forward(projections[:,:,:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}